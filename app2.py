import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import time

# Configuration de la page Streamlit
st.set_page_config(page_title="Explorateur de VAE", page_icon="üß†", layout="wide")

# Titre et introduction
st.title("üß† Explorateur de Variational Autoencoders (VAE)")
st.markdown(
    """
Cette application vous permet d'explorer les Variational Autoencoders (VAE) en modifiant leurs hyperparam√®tres
et en observant comment ils affectent l'apprentissage et la g√©n√©ration d'images.
"""
)


# D√©finition du mod√®le VAE
class VAE(nn.Module):
    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):
        super(VAE, self).__init__()

        # Encodeur
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)
        self.fc_var = nn.Linear(hidden_dim, latent_dim)

        # D√©codeur
        self.fc3 = nn.Linear(latent_dim, hidden_dim)
        self.fc4 = nn.Linear(hidden_dim, input_dim)

    def encode(self, x):
        h1 = F.relu(self.fc1(x))
        mu = self.fc_mu(h1)
        log_var = self.fc_var(h1)
        return mu, log_var

    def reparameterize(self, mu, log_var):
        std = torch.exp(0.5 * log_var)
        eps = torch.randn_like(std)
        z = mu + eps * std
        return z

    def decode(self, z):
        h3 = F.relu(self.fc3(z))
        return torch.sigmoid(self.fc4(h3))

    def forward(self, x):
        mu, log_var = self.encode(x.view(-1, 784))
        z = self.reparameterize(mu, log_var)
        return self.decode(z), mu, log_var


# Fonction pour calculer la perte
def loss_function(recon_x, x, mu, log_var, beta=1.0):
    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction="sum")
    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())
    return BCE + beta * KLD


# Fonction d'entra√Ænement
def train(model, train_loader, optimizer, device, beta):
    model.train()
    train_loss = 0
    for batch_idx, (data, _) in enumerate(train_loader):
        data = data.to(device)
        optimizer.zero_grad()
        recon_batch, mu, log_var = model(data)
        loss = loss_function(recon_batch, data, mu, log_var, beta)
        loss.backward()
        train_loss += loss.item()
        optimizer.step()

    return train_loss / len(train_loader.dataset)


# Fonction de test
def test(model, test_loader, device, beta):
    model.eval()
    test_loss = 0
    with torch.no_grad():
        for batch_idx, (data, _) in enumerate(test_loader):
            data = data.to(device)
            recon_batch, mu, log_var = model(data)
            test_loss += loss_function(recon_batch, data, mu, log_var, beta).item()

    test_loss /= len(test_loader.dataset)
    return test_loss


# Visualisation des images originales et reconstruites
def visualize_reconstruction(model, test_loader, device):
    model.eval()
    with torch.no_grad():
        # Obtenir un batch de donn√©es
        data, _ = next(iter(test_loader))
        data = data.to(device)

        # Reconstruire les images
        recon_batch, _, _ = model(data)

        # Pr√©parer l'affichage
        comparison = torch.cat(
            [data[:8].view(-1, 1, 28, 28), recon_batch[:8].view(-1, 1, 28, 28)]
        )

        # Convertir pour matplotlib
        comparison = comparison.cpu().numpy()

        fig, axes = plt.subplots(2, 8, figsize=(12, 3))
        for i in range(8):
            # Images originales
            axes[0, i].imshow(comparison[i][0], cmap="gray")
            axes[0, i].axis("off")

            # Images reconstruites
            axes[1, i].imshow(comparison[i + 8][0], cmap="gray")
            axes[1, i].axis("off")

        fig.tight_layout()
        return fig


# Visualisation de l'espace latent
def visualize_latent_space(model, test_loader, device, latent_dim):
    model.eval()
    with torch.no_grad():
        # Obtenir des donn√©es
        data_list, label_list = [], []
        for data, labels in test_loader:
            data_list.append(data)
            label_list.append(labels)
            if len(data_list) >= 10:  # Limiter √† 10 batches pour la vitesse
                break

        data = torch.cat(data_list, dim=0).to(device)
        labels = torch.cat(label_list, dim=0).to(device)

        # Encoder les donn√©es
        mu, _ = model.encode(data.view(-1, 784))
        z = mu.cpu().numpy()
        labels = labels.cpu().numpy()

        # Si la dimension latente > 2, utiliser t-SNE ou PCA
        if latent_dim > 2:
            st.warning(
                "Dimension latente > 2. Affichage des 2 premi√®res dimensions uniquement."
            )
            z = z[:, :2]  # Utilisez seulement les 2 premi√®res dimensions

        # Tracer
        fig, ax = plt.subplots(figsize=(8, 6))
        scatter = ax.scatter(z[:, 0], z[:, 1], c=labels, cmap="tab10", alpha=0.6, s=5)

        legend = ax.legend(*scatter.legend_elements(), title="Chiffres")
        ax.add_artist(legend)

        ax.set_title("Visualisation de l'espace latent")
        ax.set_xlabel("Dimension 1")
        ax.set_ylabel("Dimension 2")

        fig.tight_layout()
        return fig


# G√©n√©ration d'images √† partir de l'espace latent
def generate_from_latent(model, device, latent_dim, n_samples=10):
    model.eval()
    with torch.no_grad():
        # √âchantillonner al√©atoirement de l'espace latent
        z = torch.randn(n_samples, latent_dim).to(device)

        # D√©coder
        sample = model.decode(z).cpu().numpy()

        # Afficher les images g√©n√©r√©es
        fig, axes = plt.subplots(1, n_samples, figsize=(12, 1.5))
        for i in range(n_samples):
            axes[i].imshow(sample[i].reshape(28, 28), cmap="gray")
            axes[i].axis("off")

        fig.tight_layout()
        return fig


# Interface utilisateur Streamlit
def main():
    # Barre lat√©rale pour les hyperparam√®tres
    st.sidebar.header("Hyperparam√®tres")

    # Param√®tres du VAE
    latent_dim = st.sidebar.slider("Dimension de l'espace latent", 2, 100, 20)
    hidden_dim = st.sidebar.slider("Dimension de la couche cach√©e", 200, 800, 400)
    beta = st.sidebar.slider("Beta (poids du terme KL)", 0.1, 5.0, 1.0, 0.1)

    # Param√®tres d'entra√Ænement
    learning_rate = st.sidebar.slider(
        "Taux d'apprentissage", 0.0001, 0.01, 0.001, format="%.4f"
    )
    batch_size = st.sidebar.selectbox("Taille du batch", [32, 64, 128, 256], index=1)
    epochs = st.sidebar.slider("Nombre d'√©poques", 1, 20, 5)

    # Informations sur le dataset
    st.sidebar.header("Dataset")
    st.sidebar.info(
        """
    **MNIST** : 60 000 images d'entra√Ænement et 10 000 images de test
    de chiffres manuscrits (0-9) en noir et blanc de dimensions 28x28 pixels.
    """
    )

    # √Ä propos des VAE
    with st.expander("En savoir plus sur les VAE"):
        st.markdown(
            """
        ## Qu'est-ce qu'un VAE ?

        Un Variational Autoencoder (VAE) est un type de mod√®le g√©n√©ratif qui apprend √† repr√©senter
        des donn√©es dans un espace latent continu √† partir duquel de nouvelles donn√©es peuvent √™tre g√©n√©r√©es.

        ### Composants principaux :

        1. **Encodeur** : Transforme les donn√©es d'entr√©e en une distribution dans l'espace latent
        2. **Espace latent** : Repr√©sentation compress√©e des donn√©es (moyenne Œº et variance œÉ¬≤)
        3. **√âchantillonnage** : Utilise la "reparametrization trick" pour permettre la r√©tropropagation
        4. **D√©codeur** : Reconstruit les donn√©es originales √† partir de l'espace latent

        ### Fonction de perte :

        La fonction de perte d'un VAE comporte deux termes :
        - **Erreur de reconstruction** : Mesure la diff√©rence entre l'entr√©e et la sortie reconstruite
        - **Divergence KL** : Force la distribution latente √† se rapprocher d'une distribution normale

        Le param√®tre Œ≤ contr√¥le l'importance relative de ces deux termes.
        """
        )

    # Actions principales
    col1, col2 = st.columns(2)
    with col1:
        start_training = st.button("Entra√Æner le mod√®le")
    with col2:
        show_examples = st.button("Voir des exemples sans entra√Ænement")

    # Chargement des donn√©es
    @st.cache_resource
    def load_data(batch_size):
        transform = transforms.Compose([transforms.ToTensor()])
        train_dataset = datasets.MNIST(
            "./data", train=True, download=True, transform=transform
        )
        test_dataset = datasets.MNIST("./data", train=False, transform=transform)

        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)

        return train_loader, test_loader

    # Pr√©chargement des donn√©es
    with st.spinner("Chargement des donn√©es..."):
        train_loader, test_loader = load_data(batch_size)

    # D√©tection du device
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    device_info = f"Utilisation de {'GPU' if torch.cuda.is_available() else 'CPU'}"
    st.sidebar.info(device_info)

    # Mod√®le pr√©entra√Æn√© (pour d√©mo rapide)
    @st.cache_resource
    def get_pretrained_model():
        model = VAE(latent_dim=20).to(device)
        try:
            model.load_state_dict(
                torch.load("vae_model_pretrained.pth", map_location=device)
            )
            return model
        except BaseException:
            # Si aucun mod√®le pr√©entra√Æn√© n'est disponible, on continue
            return None

    pretrained_model = get_pretrained_model()

    # Afficher des exemples avec le mod√®le pr√©entra√Æn√©
    if show_examples and pretrained_model is not None:
        st.subheader("Exemples avec un mod√®le pr√©entra√Æn√©")

        # Afficher les reconstructions
        st.markdown("### Reconstructions d'images")
        fig_recon = visualize_reconstruction(pretrained_model, test_loader, device)
        st.pyplot(fig_recon)

        # Afficher l'espace latent
        st.markdown("### Visualisation de l'espace latent")
        fig_latent = visualize_latent_space(pretrained_model, test_loader, device, 20)
        st.pyplot(fig_latent)

        # G√©n√©rer des images
        st.markdown("### Images g√©n√©r√©es depuis l'espace latent")
        fig_gen = generate_from_latent(pretrained_model, device, 20)
        st.pyplot(fig_gen)

    # Entra√Ænement du mod√®le
    if start_training:
        st.header("Entra√Ænement du VAE")

        # Initialisation du mod√®le
        model = VAE(input_dim=784, hidden_dim=hidden_dim, latent_dim=latent_dim).to(
            device
        )
        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

        # Pr√©paration pour suivre les pertes
        train_losses = []
        test_losses = []

        # Affichage de la progression
        progress_bar = st.progress(0)
        status_text = st.empty()
        loss_chart = st.line_chart()

        # Entra√Ænement par √©poque
        for epoch in range(1, epochs + 1):
            start_time = time.time()

            # Entra√Ænement
            train_loss = train(model, train_loader, optimizer, device, beta)
            train_losses.append(train_loss)

            # Validation
            test_loss = test(model, test_loader, device, beta)
            test_losses.append(test_loss)

            # Mise √† jour de l'interface
            epoch_time = time.time() - start_time
            status_text.text(
                f"√âpoque {epoch}/{epochs} - Perte d'entra√Ænement: {train_loss:.4f}, "
                f"Perte de test: {test_loss:.4f}, Temps: {epoch_time:.2f}s"
            )

            progress_bar.progress(epoch / epochs)

            # Mise √† jour du graphique de perte
            loss_chart.add_rows(
                {"Perte d'entra√Ænement": train_loss, "Perte de test": test_loss}
            )

            # Affichage des reconstructions apr√®s certaines √©poques
            if epoch % max(1, epochs // 5) == 0 or epoch == epochs:
                st.subheader(f"R√©sultats apr√®s l'√©poque {epoch}")

                # Afficher les reconstructions
                st.markdown("#### Reconstructions d'images")
                fig_recon = visualize_reconstruction(model, test_loader, device)
                st.pyplot(fig_recon)

                # Afficher l'espace latent
                st.markdown("#### Visualisation de l'espace latent")
                fig_latent = visualize_latent_space(
                    model, test_loader, device, latent_dim
                )
                st.pyplot(fig_latent)

                # G√©n√©rer des images
                st.markdown("#### Images g√©n√©r√©es depuis l'espace latent")
                fig_gen = generate_from_latent(model, device, latent_dim)
                st.pyplot(fig_gen)

        # Sauvegarde du mod√®le
        torch.save(model.state_dict(), "vae_model_trained.pth")
        st.success("Entra√Ænement termin√© ! Le mod√®le a √©t√© sauvegard√©.")

        # Bouton pour explorer l'espace latent interactif
        if st.button("Explorer l'espace latent interactivement"):
            st.subheader("Explorateur d'espace latent")
            st.markdown(
                """
            D√©placez les curseurs pour g√©n√©rer des images √† partir de diff√©rents points de l'espace latent.
            Chaque dimension correspond √† une caract√©ristique apprise par le mod√®le.
            """
            )

            # Cr√©er des curseurs pour chaque dimension (limit√© √† 10 pour la lisibilit√©)
            max_sliders = min(10, latent_dim)
            z = torch.zeros(1, latent_dim).to(device)

            for i in range(max_sliders):
                z[0, i] = st.slider(f"Dimension {i + 1}", -3.0, 3.0, 0.0, 0.1)

            # G√©n√©rer et afficher l'image
            with torch.no_grad():
                image = model.decode(z).cpu().numpy()

                fig, ax = plt.subplots(figsize=(3, 3))
                ax.imshow(image[0].reshape(28, 28), cmap="gray")
                ax.axis("off")
                st.pyplot(fig)

            if latent_dim > max_sliders:
                st.info(
                    f"Seules les {max_sliders} premi√®res dimensions sont affich√©es pour la lisibilit√©."
                )

    # Interpolation dans l'espace latent (disponible si un mod√®le existe)
    if (pretrained_model is not None) or ("model" in locals()):
        with st.expander("Interpolation dans l'espace latent"):
            st.markdown(
                """
            Cette section vous permet de visualiser l'interpolation entre deux points dans l'espace latent.
            Cela montre comment le mod√®le g√©n√®re des transitions fluides entre les chiffres.
            """
            )

            # Utiliser le mod√®le disponible
            model_to_use = model if "model" in locals() else pretrained_model

            # Nombre de points d'interpolation
            steps = st.slider("Nombre d'√©tapes d'interpolation", 5, 20, 10)

            if st.button("G√©n√©rer interpolation"):
                # G√©n√©rer deux points al√©atoires dans l'espace latent
                z1 = torch.randn(1, model_to_use.fc_mu.out_features).to(device)
                z2 = torch.randn(1, model_to_use.fc_mu.out_features).to(device)

                # Cr√©er les points d'interpolation
                alphas = np.linspace(0, 1, steps)
                z_interp = torch.stack(
                    [z1 * (1 - alpha) + z2 * alpha for alpha in alphas]
                )

                # D√©coder les points
                with torch.no_grad():
                    interp_images = (
                        model_to_use.decode(z_interp.squeeze()).cpu().numpy()
                    )

                # Afficher les images
                fig, axes = plt.subplots(1, steps, figsize=(12, 2))
                for i in range(steps):
                    axes[i].imshow(interp_images[i].reshape(28, 28), cmap="gray")
                    axes[i].axis("off")

                st.pyplot(fig)

    # Section pour comparer diff√©rents mod√®les
    with st.expander("Comparaison de diff√©rents VAE"):
        st.markdown(
            """
        Cette section vous permet de comparer diff√©rents mod√®les VAE entra√Æn√©s avec des hyperparam√®tres variables.
        Cliquez sur le bouton ci-dessous pour entra√Æner rapidement plusieurs mod√®les avec diff√©rentes dimensions latentes.
        """
        )

        if st.button("Entra√Æner et comparer diff√©rents mod√®les (rapide)"):
            latent_dims = [2, 5, 10, 20]
            beta_values = [0.5, 1.0, 2.0]

            # Cr√©er une grille pour les r√©sultats
            grid_cols = st.columns(len(latent_dims))

            for i, lat_dim in enumerate(latent_dims):
                with grid_cols[i]:
                    st.markdown(f"#### Dim. latente = {lat_dim}")

                    # Cr√©er et entra√Æner un mod√®le rapidement (1 √©poque)
                    quick_model = VAE(latent_dim=lat_dim).to(device)
                    optimizer = torch.optim.Adam(quick_model.parameters(), lr=0.001)

                    with st.spinner(f"Entra√Ænement rapide (dim={lat_dim})..."):
                        # Entra√Ænement rapide (1 √©poque)
                        train(quick_model, train_loader, optimizer, device, beta=1.0)

                    # Afficher les reconstructions
                    fig_recon = visualize_reconstruction(
                        quick_model, test_loader, device
                    )
                    st.pyplot(fig_recon)

                    # Afficher l'espace latent
                    fig_latent = visualize_latent_space(
                        quick_model, test_loader, device, lat_dim
                    )
                    st.pyplot(fig_latent)

            # Comparer les diff√©rentes valeurs de beta
            st.markdown("### Impact du param√®tre Œ≤")
            beta_cols = st.columns(len(beta_values))

            for i, beta_val in enumerate(beta_values):
                with beta_cols[i]:
                    st.markdown(f"#### Œ≤ = {beta_val}")

                    # Cr√©er et entra√Æner un mod√®le rapidement (1 √©poque)
                    quick_model = VAE(latent_dim=10).to(device)
                    optimizer = torch.optim.Adam(quick_model.parameters(), lr=0.001)

                    with st.spinner(f"Entra√Ænement rapide (Œ≤={beta_val})..."):
                        # Entra√Ænement rapide (1 √©poque)
                        train(
                            quick_model, train_loader, optimizer, device, beta=beta_val
                        )

                    # Afficher les reconstructions
                    fig_recon = visualize_reconstruction(
                        quick_model, test_loader, device
                    )
                    st.pyplot(fig_recon)

                    # G√©n√©rer des images
                    fig_gen = generate_from_latent(quick_model, device, 10, n_samples=5)
                    st.pyplot(fig_gen)

    # Ressources suppl√©mentaires
    st.header("Ressources suppl√©mentaires")
    st.markdown(
        """
    ### Articles et tutoriels sur les VAE :
    - [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114) (Article original)
    - [Tutorial on Variational Autoencoders](https://arxiv.org/abs/1606.05908)
    - [Understanding Variational Autoencoders](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73)

    ### Applications courantes des VAE :
    - G√©n√©ration d'images
    - Compression de donn√©es
    - D√©tection d'anomalies
    - G√©n√©ration de mol√©cules
    - Synth√®se de visages
    """
    )


if __name__ == "__main__":
    main()
